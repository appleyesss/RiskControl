{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无标签样本迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、JDA 联合分布适配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JDA是一个概率分布适配的方法，适配源域和目标域的联合概率。在一个有原则的降维过程中同时适配源域和目标域的边缘分布和条件分布。JDA模型有两点假设：\n",
    "\n",
    "- 源域和目标域边缘分布不同\n",
    "- 源域和目标域条件分布不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用JDA模型对样本域进行映射，从而提高模型在目标域的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg.misc import norm\n",
    "from scipy.sparse.linalg import eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JDA(Xs,Xt,Ys,Yt,k=100,lamba=0.1,ker='primal',gamma=1.0,data='default'):\n",
    "    X = np.hstack((Xs,Xt))\n",
    "    X = np.diag(1/np.sqrt(np.sum(X**2)))\n",
    "    (m,n) = X.shape\n",
    "    # 源域样本量\n",
    "    ns = Xs.shape[1]\n",
    "    # 目标域样本量\n",
    "    nt = Xt.shape[1]\n",
    "    # 分类个数\n",
    "    C = len(np.unique(Ys))\n",
    "    # 生成MMD矩阵\n",
    "    e1 = 1/ns*np.ones((ns,1))\n",
    "    e2 = 1/nt*np.ones((nt,1))\n",
    "    e = np.vstack((e1,e2))\n",
    "    M = np.dot(e,e.T)*C\n",
    "    \n",
    "    # 除0，null，False以外都可运行\n",
    "    if any(Yt) and len(Yt)==nt:\n",
    "        for c in np.reshape(np.unique(Ys), -1, 1):\n",
    "            e1 = np.zeros((ns,1))\n",
    "            e1[Ys == c] = 1/len(Ys[Ys == c])\n",
    "            e2 = np.zeros((nt,1))\n",
    "            e2[Yt == c] = -1/len(Yt[Yt == c])\n",
    "            e = np.hstack((e1,e2))\n",
    "            e = e[np.isinf(e) == 0]\n",
    "            M = M+np.dot(e,e.T)\n",
    "    \n",
    "    # 矩阵迹求平方根\n",
    "    M = M/norm(M, ord = 'fro')\n",
    "    \n",
    "    # 计算中心矩阵\n",
    "    H = np.eye(n) - 1/(n)*np.ones((n,n))\n",
    "    \n",
    "    # JDA\n",
    "    if ker == 'primal':\n",
    "        # 特征值特征向量\n",
    "        A = eigs(np.dot(np.dot(X,M),X.T) + lamda*np.eye(m),\n",
    "                 k=k, M=np.dot(np.dot(X,H),X.T), which='SM')\n",
    "        Z = np.dot(A.T,X)\n",
    "    else:\n",
    "        pass\n",
    "    return A,Z  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、DTELM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTELM是一种在极限学习机（ELM）上改进得到的迁移学习方法，使用MMD（源域一直变换直到匹配目标域，匹配的度量方式就是MMD最大均值差异）距离衡量分布的差异，并模型迭代过程中缩小差异。DTELM分为两部分：\n",
    "\n",
    "- 对目标域数据的自编码映射\n",
    "- 针对源域数据的域对齐映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeros()返回返回来一个给定形状和类型的用0填充的数组\n",
    "# np.ones()返回一个全1的n维数组\n",
    "# np.hstack() 将参数元组的元素数组按水平方向进行叠加\n",
    "# np.sort() 排序 默认/axis = 1 按行排序， axis = 0 按列排序\n",
    "# np.eye() 生成主对角线、独热编码\n",
    "# np.linalg.inv 求逆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTELM(Train_s, Train_t, Test_t, NL, Type=\"CALSSFIER\", Num_hid=100, Active_Function=\"sig\"):\n",
    "    '''\n",
    "    Train_s：源域训练集\n",
    "    Train_t：目标域训练集\n",
    "    Test_t：目标域测试集\n",
    "    Type：模型类型（分类：\"CLASSIFIER\"，回归：\"REGRESSION\"）  \n",
    "    Num_hid：隐层神经元个数，默认100个 \n",
    "    Active_Function：映射函数（\" sigmoid \":sigmoid函数, \"sin\":正弦函数）\n",
    "    NL：模型选择  \n",
    "    '''\n",
    "    \n",
    "    Cs = 0.01\n",
    "    Ct = 0.01\n",
    "    \n",
    "    REGRESSION=0  \n",
    "    CLASSIFIER=1\n",
    "    \n",
    "    # 训练数据\n",
    "    T = Train_s[:,0].T\n",
    "    P = Train_s[:,1:Train_s.shape[1]].T\n",
    "    \n",
    "    # 目标域数据\n",
    "    Tt = Train_t[:,0].T\n",
    "    Pt = Train_t[:,1:Train_t.shape[1]].T\n",
    "    \n",
    "    # 测试集数据\n",
    "    TVT = Test_t[:,0].T\n",
    "    TVP = Test_t[:,2:Test_t.shape[1]].T\n",
    "    \n",
    "    Num_train = P.shape[1]\n",
    "    Num_train_target = Pt.shape[1]\n",
    "    Num_test = TVP.shape[1]\n",
    "    Num_input = P.shape[0]\n",
    "    \n",
    "    if Type is not \"REGRESSION\":\n",
    "        sorted_target = np.sort(np.hstack((T,TVT)))\n",
    "        label = np.zeros((1,1))\n",
    "        label[0,0] = sorted_target[0,0]\n",
    "        j = 0\n",
    "        for i in range(2,(Num_train+Num_test+1)):\n",
    "            if sorted_target[0,i-1] != label[0,j-1]:\n",
    "                j=j+1\n",
    "                label[0,j-1] = sorted_target[0,i-1]\n",
    "        \n",
    "        number_class = j+1\n",
    "        Num_output = number_class\n",
    "        \n",
    "        temp_T = np.zeros(Num_output, Num_train)\n",
    "        for i in range(1,Num_train+1):\n",
    "            for j in range(1,number_class+1):\n",
    "                if label(0,j-1) == T(0,i-1):\n",
    "                    break\n",
    "            temp_T[j-1, i-1] = 1\n",
    "        T = temp_T*2 - 1\n",
    "        \n",
    "        Tt_m = np.zeros(Num_output , Num_train_Target)\n",
    "        for i in range(1,Num_train_Target+1):\n",
    "            for j in range(1,number_class+1):\n",
    "                if label(0,j-1) == T(0,i-1):\n",
    "                    break\n",
    "            Tt_m[j-1, i-1] = 1\n",
    "        Tt = Tt_m*2 -1\n",
    "            \n",
    "        \n",
    "        temp_TV_T = np.zeros(Num_output,Num_test)\n",
    "        for i in range(1,Num_test):\n",
    "            for j in range(1,number_class+1):\n",
    "                if label(0,j-1) == T(0,i-1):\n",
    "                    break\n",
    "            temp_TV_T[j-1, i-1] = 1\n",
    "        TVT = temp_TV_T*2 -1\n",
    "    \n",
    "    Inputweight = np.random.rand(Num_hid,Num_input)*2-1\n",
    "    Bis_hid = np.random.rand(Num_hid, 1)\n",
    "    H_m = Inputweight*P\n",
    "    Ht_m = Inputweight*Pt\n",
    "    del P\n",
    "    del Pt\n",
    "    \n",
    "    ind = np.ones(1,Num_train)\n",
    "    indt = np.ones(1,Num_train_Target)\n",
    "    BiasMatrix = Bis_hid[:,ind-1]  \n",
    "    BiasMatrixT = Bis_hid[:,indt-1]\n",
    "    H_m = H_m + BiasMatrix\n",
    "    Ht_m = Ht_m + BiasMatrixT\n",
    "    \n",
    "    if Active_Function == \"sigmoid\":\n",
    "        # sigmoid公式\n",
    "        H = 1/(1+np.exp(-H_m)) \n",
    "        Ht = 1/(1+np.exp(-Ht_m))\n",
    "    if Active_Function == \"sin\":\n",
    "        H = np.sin(H_m)\n",
    "        Ht = np.sin(Ht_m)\n",
    "    if Active_Function != \" sigmoid \" and Active_Function!=\"sin\":\n",
    "        pass\n",
    "    \n",
    "    del H_m\n",
    "    del Ht_m\n",
    "    \n",
    "    n = Num_hid\n",
    "    \n",
    "    '''\n",
    "    DTELM模型\n",
    "    '''\n",
    "    H = H.T  \n",
    "    Ht = Ht.T  \n",
    "    T =T.T  \n",
    "    Tt = Tt.T\n",
    "    \n",
    "    if NL == 0:\n",
    "        A = Ht*H.T\n",
    "        B = Ht*Ht.T + np.eye(Num_train_Target)/Ct\n",
    "        C = H*Ht.T\n",
    "        D = H*H.T + np.eye(Num_train)/Cs\n",
    "        ApT = np.linalg.inv(B)*Tt-np.linalg.inv(B)*A* \\\n",
    "              np.linalg.inv(C*np.linalg.inv(B)*A-D)* \\\n",
    "              (C*np.linalg.inv(B)*Tt-T)\n",
    "        ApS = inv(C*np.linalg.inv(B)*A-D)*(C*np.linalg.inv(B)*Tt-T)\n",
    "        Outputweight = H.T*ApS+Ht.T*ApT\n",
    "    else:\n",
    "        Outputweight = np.linalg.inv(np.eye(n)+Cs*H.t*H+Ct*Ht.T*Ht)* \\\n",
    "                       (Cs*H.T*T+Ct*Ht.T*Tt)\n",
    "    \n",
    "    # 计算准确率\n",
    "    Y = (H * OutputWeight).T\n",
    "    H_m_test = InputWeight*TVP\n",
    "    ind = np.ones(1,Num_hid)\n",
    "    BiasMatrix = Bis_hid[:,ind-1]\n",
    "    H_m_test = H_m_test+BiasMatrix\n",
    "    if Active_Function == \"sig\":\n",
    "        H_test = 1/(1+np.exp(-H_m_test))\n",
    "    if Active_Function == \"sin\":\n",
    "        H_test = np.sin(H_m_test)\n",
    "        \n",
    "    TY = (H_test.T*OutputWeight).T\n",
    "    \n",
    "    # 返回测试集结果\n",
    "    if Type ==\"CLASSIFIER\":\n",
    "        return TY\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迁移学习为模型带来了样本上的扩充，但同时也造成精度的下降以及模型的不稳定性。\n",
    "\n",
    "可以通过多模型组合来平衡迁移学习的不稳定，多模型加权输出最终结果，可以为模型引入更稳健的决策因子。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
